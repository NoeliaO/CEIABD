{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eab1a4f8-6c44-4ea6-8647-95a63b091219",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# SPARK BÁSICO - 01\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) RDD II. Más manipulación con RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dd45e8d-e749-4580-bf49-8d52a8a327ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un RDD con la tupla (dateId, tempValue)\n",
    "\n",
    "rdd_data = sc.parallelize([(20230101, 23), (20230101, 24.5), (20230101, 21), (20230101, 23), (20230102, 24), (20230102, 27), (20230102, 28), (20230102, 26)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58d5a6c2-0a79-48a2-82a9-ec0531cf6d97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Usamos Map and Reduce para obtener la media por dateId mediante una expresión lambda\n",
    "\n",
    "rdd_temp = (rdd_data\n",
    "            .map(lambda x: (x[0], (x[1], 1)))\n",
    "            .reduceByKey(lambda x,y: (x[0] +y[0], x[1] +y[1]))\n",
    "            .map(lambda x: (x[0], x[1][0]/x[1][1]))     \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d19a1c-0a91-4b48-a403-cfd16679ca1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20230101, 22.875)\n(20230102, 26.25)\n"
     ]
    }
   ],
   "source": [
    "dataColl=rdd_temp.collect()\n",
    "for row in dataColl:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06688e1-f320-403d-9c41-feed9ba7e325",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un Dataframe con la tupla (dateId, tempValue)\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_data = spark.createDataFrame([(20230101, 23.0), (20230101, 24.5), (20230101, 21.0), (20230101, 23.0), (20230102, 24.0), (20230102, 27.0), (20230102, 28.0), (20230102, 26.0)],[\"dateid\", \"tempValue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b456ec4-d53c-4656-9c81-e01ad2e64e74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupamos para obtener la media por dateId \n",
    "df_avg = df_data.groupBy(\"dateId\").agg(avg(\"tempValue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f638bf7-1bcf-48d5-bbb9-46b09270c8ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n|  dateId|avg(tempValue)|\n+--------+--------------+\n|20230101|        22.875|\n|20230102|         26.25|\n+--------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_avg.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark - 01 - RDD II - Más manipulación con RDDs",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
