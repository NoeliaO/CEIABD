{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![FOTO](./img/logo.jpeg)  -->\n",
    "# ***Deep Vision para tareas de clasificación***\n",
    "## ***By Noelia Otazo Rojo***\n",
    "\n",
    "### Objetivos\n",
    "**Evaluar y comparar** estrategias para la **clasificación de imágenes**, la solución deberá estar basada en el **aprendizaje profundo (Redes Neuronales Convolucionales CNNs)**.\n",
    "\n",
    "### Contenidos\n",
    "1.   **Carga** del conjunto de datos\n",
    "2.   **Inspección** del conjunto de datos\n",
    "3.   **Acondicionamiento** del conjunto de datos\n",
    "4.   Desarrollo de la **arquitectura** de red neuronal y **entrenamiento** de la solución\n",
    "5.   **Monitorización** del proceso de **entrenamiento** para la toma de decisiones\n",
    "6.   **Evaluación** del modelo predictivo.\n",
    "\n",
    "### Fuente de datos\n",
    "Enlace al dataset que voy a utilizar para llevar a cabo el siguiente proyecto:\n",
    "[Cancer Detection](https://www.kaggle.com/c/histopathologic-cancer-detection/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparación del proyecto.\n",
    "En esta sección añadimeros las sentencias de instalación y las importaciones de las librerías necesarias para el desarrollo del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo ejecuitar una vez\n",
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación será necesario importar las librerías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "\n",
    "# OpenCV to process images\n",
    "import cv2\n",
    "\n",
    "# Necesario para la tranformación de las imagenes de tif a png\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "# Directory indexes\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Ploteado del esquema gráfico del modelo\n",
    "# from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conjunto de datos.\n",
    "En esta sección cargaremos el contenido del dataset para su posterior uso.\n",
    "\n",
    "### 1.1 Carga del conjunto de datos.\n",
    "De este modo tendremos ya almacenado en variables las ubicaciones de los ficheros de labels así como la ruta a la carpeta que contiene las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "test_data_path = 'histopathologic-cancer-detection/test'\n",
    "train_data_path = 'histopathologic-cancer-detection/train'\n",
    "train_labels = pd.read_csv('histopathologic-cancer-detection/train_labels.csv')\n",
    "validation_labels = pd.read_csv('histopathologic-cancer-detection/validation_labels.csv')\n",
    "\n",
    "# Obtiene los nombres de clase únicos como una lista\n",
    "class_names = train_labels['label'].unique().tolist()\n",
    "\n",
    "# Asegúrate de que los nombres de clase sean strings si es necesario\n",
    "class_names = [str(name) for name in class_names]\n",
    "print(train_labels.head())\n",
    "print(validation_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 Distribución train / test \n",
    "A continuación generaremos un gráfico para comprobar la distribución del contenido de train/test, ya que venía ya distribuído desde Kaggle, por lo que no será necesrio hacer un nuevo split de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un Path object para el directorio de entrenamiento\n",
    "paths_train_dataset = list(Path(train_data_path).rglob('*.tif'))\n",
    "paths_test_dataset = list(Path(test_data_path).rglob('*.tif'))\n",
    "\n",
    "# Combinamos ambos paths para conseguir el conteo total\n",
    "paths_dataset = paths_train_dataset + paths_test_dataset\n",
    "\n",
    "dict_dataset = defaultdict(list)\n",
    "\n",
    "# Agrupa las imágenes por su carpeta (train o test)\n",
    "for p in paths_dataset:\n",
    "    dict_dataset[p.parent.name].append(str(p))\n",
    "\n",
    "# Imprime la cantidad y la proporción de imágenes por carpeta\n",
    "for k in dict_dataset.keys():\n",
    "    print(f'La carpeta {k} tiene {len(dict_dataset[k])} elementos con proporción {len(dict_dataset[k])/len(paths_dataset):.2f}')\n",
    "\n",
    "# Configura los parámetros de la figura para matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "\n",
    "# Crea el gráfico de barras horizontal\n",
    "plt.barh(y=list(dict_dataset.keys()), width=[len(dict_dataset[k]) for k in dict_dataset.keys()])\n",
    "plt.title('Distribución por carpetas')\n",
    "plt.xlabel('Número de imágenes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La misma comprobación pero en un gráfico de sectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_index = {k: i for i, k in enumerate(dict_dataset.keys())}\n",
    "names_proportion = {k: len(dict_dataset[k])/len(paths_dataset) for k in dict_dataset.keys()}\n",
    "print('Los índices por clase son: ')\n",
    "pprint(names_to_index)\n",
    "print('\\n')\n",
    "print('La distribución de los datos por clase es:')\n",
    "pprint(names_proportion)\n",
    "\n",
    "plt.pie(names_proportion.values(), labels=names_proportion.keys())\n",
    "plt.title('Distribución de los datos en el dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Visualización de los datos\n",
    "Comprobamos que los datos son accesibles y que los podemos mostrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = random.choice(paths_dataset)\n",
    "\n",
    "plt.imshow(cv2.imread(str(sample_path))[..., ::-1])\n",
    "plt.title(sample_path.parent.name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Formateo de las imágenes\n",
    "Dado que las imágenes se encuentran en un formato .tif y para poder procesarlas necesitaremos un formato que esté aceptado por Tensorflow, las transformaremos a imágenes .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la ruta de origen y destino\n",
    "src_path = pathlib.Path('histopathologic-cancer-detection/train')\n",
    "def convert_image(src_path):\n",
    "    dest_path = pathlib.Path('histopathologic-cancer-detection/train_converted')\n",
    "\n",
    "    # Crea el directorio de destino si no existe\n",
    "    dest_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convierte cada archivo .tif a .png\n",
    "    for tif_image_path in src_path.glob('*.tif'):\n",
    "        # Cargar la imagen .tif\n",
    "        image = Image.open(tif_image_path)\n",
    "        # Definir el nombre de archivo de destino con la extensión .png\n",
    "        dest_image_path = dest_path / (tif_image_path.stem + '.png')\n",
    "        # Guardar la imagen en formato .png\n",
    "        image.save(dest_image_path, 'PNG')\n",
    "\n",
    "# Ejecutar solo una vez\n",
    "# convert_image(src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos lo mismo para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la ruta de origen y destino\n",
    "test_path = pathlib.Path('histopathologic-cancer-detection/test')\n",
    "\n",
    "def convert_image_test(src_path):\n",
    "    dest_path = pathlib.Path('histopathologic-cancer-detection/test_converted')\n",
    "\n",
    "    # Crea el directorio de destino si no existe\n",
    "    dest_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convierte cada archivo .tif a .png\n",
    "    for tif_image_path in src_path.glob('*.tif'):\n",
    "        # Cargar la imagen .tif\n",
    "        image = Image.open(tif_image_path)\n",
    "        # Definir el nombre de archivo de destino con la extensión .png\n",
    "        dest_image_path = dest_path / (tif_image_path.stem + '.png')\n",
    "        # Guardar la imagen en formato .png\n",
    "        image.save(dest_image_path, 'PNG')\n",
    "\n",
    "# Ejecutar solo una vez\n",
    "# convert_image_test(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si existen imágenes en el nuevo directorio de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "train_path = pathlib.Path('histopathologic-cancer-detection/train_converted')\n",
    "\n",
    "# Comprobar si existen imágenes en el directorio\n",
    "png_images = list(train_path.glob('*.png'))\n",
    "if not png_images:\n",
    "    print(f\"No se encontraron imágenes en {train_path}.\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(png_images)} imágenes en {train_path}.\")\n",
    "\n",
    "# Crea un dataset a partir de los archivos de imagen\n",
    "train_dataset = tf.data.Dataset.list_files(str(train_path/'*.png'), shuffle=True)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si existen imágenes en el nuevo directorio de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "test_path = pathlib.Path('histopathologic-cancer-detection/test_converted')\n",
    "\n",
    "# Comprobar si existen imágenes en el directorio\n",
    "png_images = list(test_path.glob('*.png'))\n",
    "if not png_images:\n",
    "    print(f\"No se encontraron imágenes en {test_path}.\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(png_images)} imágenes en {test_path}.\")\n",
    "\n",
    "# Crea un dataset a partir de los archivos de imagen\n",
    "test_dataset = tf.data.Dataset.list_files(str(test_path/'*.png'), shuffle=True)\n",
    "\n",
    "print(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Dataframe\n",
    "Este proceso fue necesario llevarlo a cabo mediante etapas ya que el rendimiento del PC sobre el que se realizó el proceso no permitía cargar todos los archivos de imagen de una única vez.   \n",
    "   \n",
    "Creación del dataframe de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas a los directorios y archivos\n",
    "train_dir = 'histopathologic-cancer-detection/train_converted'\n",
    "train_labels_csv = 'histopathologic-cancer-detection/train_labels.csv'\n",
    "\n",
    "# Cargar las etiquetas\n",
    "labels_df = pd.read_csv(train_labels_csv)\n",
    "labels_df['id'] = labels_df['id'].apply(lambda x: x + '.png')  # Asegurarte de que los IDs tienen la extensión .png\n",
    "\n",
    "# Crear un generador de imágenes que también realiza la normalización de las mismas\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Este generador carga las imágenes directamente del disco en lotes, por lo que no es necesario cargar todas las imágenes en la memoria a la vez\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory=train_dir,\n",
    "    x_col='id',  # Nombre del archivo de la imagen\n",
    "    y_col='label',  # Columna con las etiquetas\n",
    "    class_mode='raw',  # Tipo de problema de clasificación (binary para 0 o 1)\n",
    "    target_size=(224, 224),  # Tamaño al que se redimensionarán las imágenes\n",
    "    batch_size=32,  # Tamaño de los lotes de datos\n",
    "    shuffle=True  # Mezclar los datos de manera aleatoria\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respetimos el porceso para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'histopathologic-cancer-detection/test_converted'\n",
    "validation_labels = pd.read_csv('histopathologic-cancer-detection/validation_labels.csv')\n",
    "\n",
    "# Cargar las etiquetas de validación\n",
    "validation_labels['id'] = validation_labels['id'].apply(lambda x: x + '.png')  # Asegurarte de que los IDs tienen la extensión .png\n",
    "\n",
    "# Crear un generador de imágenes que también realiza la normalización de las mismas para validación\n",
    "datagen_validation = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Este generador carga las imágenes de validación directamente del disco en lotes\n",
    "validation_generator = datagen_validation.flow_from_dataframe(\n",
    "    dataframe=validation_labels,\n",
    "    directory=test_path,\n",
    "    x_col='id',  # Nombre del archivo de la imagen\n",
    "    y_col='label',  # Columna con las etiquetas\n",
    "    class_mode='raw',  # Uso de 'raw' para etiquetas numéricas\n",
    "    target_size=(224, 224),  # Tamaño al que se redimensionarán las imágenes\n",
    "    batch_size=32,  # Tamaño de los lotes de datos\n",
    "    shuffle=True  # Mezclar los datos de manera aleatoria\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación visualizaremos algunos datos con la finalidad de verificar como se ven las imágenes del conjunto de datos y si las transformaciones están funcionando como se esperaba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración ansiosa activada para depuración (si necesario)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Define una figura con un tamaño específico\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Toma un lote del dataset\n",
    "images, labels = train_generator.next()  # Obtiene un lote directamente\n",
    "print(\"Images shape:\", images.shape)  # Imprime la forma del tensor de imágenes\n",
    "print(\"Labels shape:\", labels.shape)  # Imprime la forma del tensor de etiquetas\n",
    "\n",
    "# Determina el número de imágenes a visualizar\n",
    "num_images = images.shape[0]\n",
    "num_subplots = min(num_images, 9)  # Limita a mostrar máximo 9 imágenes\n",
    "\n",
    "for i in range(num_subplots):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    img = images[i]  # Las imágenes ya están en formato adecuado para visualización\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Las etiquetas ya están en formato correcto dado que class_mode='raw' las proporciona como numéricas\n",
    "    label = labels[i]  # Directamente mostrar la etiqueta asociada\n",
    "\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo de Deep Vision\n",
    "\n",
    "El siguiente paso será la creación del modelo de Deep Vision. En este proceso tendremos que establecer los parámetros con los que queremos entrenar a la red, escoger el modelo a usar y entrenarlo.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Establecemos los parámetros\n",
    "\n",
    "A continuación estableceremos los parámetros con los que queremos entrenar a la red, escoger el modelo a usar y entrenarlo. Estos parámetros serán:\n",
    "- **batch_size**: Define el número de muestras que se procesan antes de que los pesos del modelo cambien.\n",
    "- **monitor**: Especifica la métrica que se utilizará para monitorizar el rendimiento del modelo durante el entrenamiento.\n",
    "- **learning_rate**: Define el tamaño del paso que se utiliza para actualizar los pesos del modelo en cada iteración del entrenamiento.\n",
    "- **epochs**: Es el número total de veces que el conjunto de entrenamiento completo se pasa a través del modelo.\n",
    "- **early_stopping_patience**: Define cuántas épocas sin mejora en la métrica monitorizada (val_loss) deben transcurrir antes de detener el entrenamiento de manera anticipada.\n",
    "- **train_backbone**: Determina si las capas base del modelo preentrenado deben ser entrenables o no.\n",
    "- **version**: Parámetro personalizado, utilizado para versionar modelos y resultados.\n",
    "- **plateau_factor**: Factor por el cual se reducirá el learning_rate cuando se detecte un estancamiento en la mejora de la métrica monitorizada.\n",
    "- **plateau_patience**: Número de épocas que deben pasar sin mejora antes de reducir el learning_rate.\n",
    "\n",
    "Configuración del modelo:\n",
    "- **input_shape**: Define las dimensiones de las imágenes de entrada al modelo. En este caso, cada imagen tiene un tamaño de 224x224 píxeles con 3 canales de color (RGB).\n",
    "- **model_name**: Especifica el modelo base que se utilizará. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params \n",
    "# Train \n",
    "batch_size = 8\n",
    "monitor = 'val_loss'\n",
    "learning_rate = 1e-4\n",
    "epochs = 50\n",
    "early_stopping_patience = 4\n",
    "train_backbone = True\n",
    "version = 0\n",
    "plateau_factor = 0.5\n",
    "plateau_patience = 2\n",
    "\n",
    "# Model \n",
    "input_shape = (224, 224, 3)\n",
    "model_name = 'NOR-RN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Técnica de aumento de datos\n",
    "Esta técnica ayudan a mejorar la generalización del modelo al introducir variabilidad en el conjunto de datos de entrenamiento, lo que permite que el modelo aprenda a reconocer patrones importantes en condiciones variadas y evita que se ajuste demasiado a los datos específicos de entrenamiento (overfitting).\n",
    "- **RandomFlip(\"horizontal_and_vertical\")**: Esta capa aplica un volteo aleatorio a las imágenes tanto horizontal como verticalmente. Al hacer esto, el modelo puede aprender a reconocer objetos sin importar su orientación en la imagen.\n",
    "- **RandomRotation((-1, 1), fill_mode='reflect', interpolation='nearest')**: Rota las imágenes un ángulo aleatorio dentro del rango especificado (en este caso, de -360 a 360 grados, ya que -1 y 1 se interpretan como fracciones de una vuelta completa en círculo). fill_mode='reflect' indica que los píxeles faltantes a causa de la rotación serán rellenados reflejando los píxeles en el borde de la imagen. interpolation='nearest' se refiere a cómo se calculan los valores de los nuevos píxeles que aparecen durante la transformación; en este caso, se asigna el valor del píxel más cercano.\n",
    "- **RandomZoom(width_factor=(0, 0.2), height_factor=(0, 0.2), interpolation='nearest')**: Aplica un zoom aleatorio a las imágenes. Los factores de zoom para la anchura y la altura se establecen entre 0 (sin cambio) y 0.2 (un aumento de hasta el 20%). Al igual que con la rotación, interpolation='nearest' se usa para determinar cómo llenar los nuevos píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "[\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation((-1, 1), fill_mode='reflect', interpolation='nearest'),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(width_factor=(0, 0.2), height_factor=(0, 0.2), interpolation='nearest'),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modelo \n",
    "Crearemos un modelo que permita procesar dichas imagenes y determinar mediante una clasificación binaria (0 y 1 si el paciente está afectado por la patología).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo estará formado por capas:\n",
    "- **Primera capa**\n",
    "    - *data_augmentation :* Antes de nada añadiremos el data_augmentation que anteriormente hemos declarado, se añade como la primera capa de la red. Esto significa que cada imagen que ingrese al modelo será primero procesada por la capa de aumento de datos antes de pasar a través de las capas convolucionales y densas.\n",
    "- **Segunda capa**\n",
    "    - *Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)):* Esta es una **capa convolucional**. \n",
    "        - Los parámetros indican que tiene **32 filtros (o kernels)**, cada uno de tamaño 3x3. \n",
    "        - La función de activación 'relu' (Rectified Linear Unit) se utiliza para añadir no linealidad al modelo, ayudando a aprender patrones más complejos en los datos.\n",
    "        - input_shape=(224, 224, 3) define el tamaño de las imágenes de entrada al modelo, en este caso, imágenes de 224x224 píxeles con 3 canales de color (RGB).\n",
    "    - *MaxPooling2D(2, 2):* Esta capa realiza una operación de max pooling con una ventana de 2x2. Reduce la dimensionalidad espacial (ancho y alto) de la entrada, lo que ayuda a hacer el modelo más eficiente y a reducir el overfitting. Al seleccionar el máximo valor de cada ventana 2x2, se conservan las características más destacadas.\n",
    "- **Tercera capa**\n",
    "    - *Conv2D(64, (3,3), activation='relu'):* Otra capa convolucional, esta vez con **64 filtros**. Aumentar el número de filtros permite al modelo capturar más detalles o características de las imágenes.\n",
    "    - *MaxPooling2D(2,2):* Otro max pooling para reducir más la dimensión de las características.\n",
    "- **Cuarta capa**\n",
    "    - *Conv2D(128, (3,3), activation='relu'):* Aumenta aún más el **número de filtros a 128**. A medida que profundizamos en la red, es común aumentar el número de filtros para permitir que la red capture la complejidad de los datos. Se sigue utilizando la activación 'relu'.\n",
    "    - *MaxPooling2D(2,2):* Última capa de max pooling, sigue reduciendo la dimensión.\n",
    "- **Quinta capa**\n",
    "    - *Flatten():* Esta capa **aplana los mapas de características en un vector**. Esto es necesario porque las siguientes capas (densas) esperan vectores de entrada en lugar de matrices 3D.\n",
    "- **Sexta capa**\n",
    "    - *Dense(512, activation='relu'):* Una capa densa (también conocida como capa completamente conectada) que tiene 512 unidades. Esta capa puede aprender combinaciones no lineales de las características extraídas por las capas convolucionales. Usa 'relu' para la activación.\n",
    "- **Séptima capa**\n",
    "    - *Dropout(0.5):* Esta capa descarta aleatoriamente el 50% de las características durante el entrenamiento. Esto ayuda a prevenir el overfitting al forzar a la red a aprender patrones redundantes, haciendo el modelo más robusto.\n",
    "- **Octava capa**\n",
    "    - *Dense(1, activation='sigmoid'):* Es la **última capa densa con una sola unidad**. Usa la **función de activación 'sigmoid'** porque estás realizando una clasificación binaria. Esta función mapea la salida de la red a un valor entre 0 y 1, interpretado como la probabilidad de que la entrada pertenezca a la clase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        data_augmentation,\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Callbacks\n",
    "Las callbacks permiten realizar acciones específicas en diferentes etapas del entrenamiento del modelo. Cada callback que has mencionado tiene un propósito particular que puede ayudar a mejorar el rendimiento del modelo, ahorrar recursos, o proporcionar información adicional sobre el proceso de entrenamiento.\n",
    "- **ModelCheckpoint**: Este callback guarda automáticamente el modelo o los pesos del modelo en un archivo, en ciertos intervalos, lo que te permite recuperar y usar el modelo sin tener que reentrenarlo.\n",
    "    - **save_best_only=True**: Indica que el modelo se guardará solo cuando su desempeño en la métrica monitorizada sea el mejor hasta el momento.\n",
    "    - **f'weights/{model_name}/version_{version}'**: La ruta especifica dónde se guardarán los archivos del modelo, incluyendo detalles como el nombre del modelo y la versión, lo que facilita la organización y el acceso a diferentes versiones o configuraciones de entrenamiento.\n",
    "- **EarlyStopping**: Detiene el entrenamiento cuando una métrica monitorizada ha dejado de mejorar, lo cual ayuda a prevenir el sobreajuste y a ahorrar tiempo y recursos si el entrenamiento ya no está siendo productivo.\n",
    "    - **patience=early_stopping_patience**: Configura cuántas épocas deben pasar sin mejora antes de detener definitivamente el entrenamiento. Esto proporciona un margen para confirmar que el rendimiento realmente ha dejado de mejorar y no es solo una fluctuación en los datos.\n",
    "- **ReduceLROnPlateau**: Reduce la tasa de aprendizaje (learning rate) cuando una métrica monitorizada ha dejado de mejorar.\n",
    "    - **factor=plateau_factor**: Especifica el factor de reducción de la tasa de aprendizaje. En este caso, se establece en 0.5, lo que significa que la tasa de aprendizaje se reducirá en un 50% cada vez que la métrica monitorizada no mejore.\n",
    "    - **patience=plateau_patience**:  Especifica cuántas épocas sin mejora deben pasar antes de reducir la tasa de aprendizaje, permitiendo algunas fluctuaciones antes de hacer un ajuste.\n",
    "- **TensorBoard**: Proporciona una manera de visualizar diferentes métricas de entrenamiento y validación en tiempo real, usando una interfaz gráfica en el navegador.\n",
    "    - **log_dir=f'weights/{model_name}/version_{version}'**: Establece el directorio donde se guardarán los logs de TensorBoard, lo que permite un fácil seguimiento y comparación de diferentes experimentos o versiones de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(f'weights/{model_name}/version_{version}', save_best_only=True, monitor=monitor),\n",
    "    keras.callbacks.EarlyStopping(monitor=monitor, patience=early_stopping_patience, mode='auto'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=plateau_factor, patience=plateau_patience, mode='auto'),\n",
    "    keras.callbacks.TensorBoard(log_dir=f'weights/{model_name}/version_{version}')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Compilación del modelo\n",
    "El siguiente paso será compilar el modelo, para ello utilizaremos el optimizador de Adam que es uno de los optimizadores más comunes y efectivos en entrenamientos de redes neuronales, especialmente conocido por manejar bien las tasas de aprendizaje adaptativas para diferentes parámetros. Y detallaremos valores como:\n",
    "\n",
    "- **loss='binary_crossentropy'**: Esta función mide el rendimiento del modelo cuantificando la diferencia entre las etiquetas reales y las predicciones, ideal para situaciones donde las etiquetas son 0 o 1.\n",
    "- **metrics**: Estas son las medidas que utilizas para juzgar el rendimiento del modelo. Incluyen:\n",
    "    - **Precisión**: Proporción de identificaciones positivas que fueron realmente correctas.\n",
    "    - **Recuerdo (Recall)**: Proporción de casos positivos reales que fueron identificados correctamente.\n",
    "    - **Exactitud Binaria (BinaryAccuracy)**: Mide la frecuencia con la que las predicciones del modelo coinciden con las etiquetas binarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        keras.metrics.BinaryAccuracy(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Entrenamiento del modelo\n",
    "A continuación habrá que entrenar el modelo, para ello será necesario establecer unos valores a dicho entrenamiento:\n",
    "- **model.fit()**: Este método es donde ajustas los pesos de tu modelo utilizando tus datos de entrenamiento.\n",
    "- **train_generator**: Es el generador que alimenta datos al modelo en lotes, permitiendo el uso eficiente de memoria y posiblemente incorporando más aumentos de datos en tiempo real.\n",
    "- **epochs**: Número total de ciclos completos a través del conjunto de entrenamiento completo que el modelo debería ejecutar durante el entrenamiento.\n",
    "- **steps_per_epoch**: Total de número de pasos antes de que se declare una época terminada y comience la siguiente época. Normalmente, es el número de muestras dividido por el tamaño del lote.\n",
    "- **validation_data**: Datos contra los cuales evaluarás el modelo al final de cada época. \n",
    "- **validation_steps**: Define cuántos lotes de muestras del conjunto de validación serán evaluados.\n",
    "- **verbose=1**: Controla la cantidad de salida de información que se muestra durante el entrenamiento; 1 significa que mostrará una barra de progreso.\n",
    "- **callbacks**: Lista de callbacks que se aplicarán durante el entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "H = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Gráfica de losses\n",
    "Permite visualizar la evolución de la pérdida de entrenamiento y la pérdida de validación a lo largo de las épocas durante el entrenamiento de tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficas losses\n",
    "epochs_trained = len(H.history['loss'])\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs_trained), H.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, epochs_trained), H.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.title(f'Training and Val Loss {model_name}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(f'weights/{model_name}/version_{version}/losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Inferencia y evaluación\n",
    "Por último tendremos que ejecutar inferencias en un conjunto de datos de prueba y calcular métricas de clasificación para evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegura modelo esté limpio antes de cargar uno nuevo\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "print('Loading model from checkpoint ...')\n",
    "model_path = f'weights/{model_name}/version_{version}'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print('Model loaded!')\n",
    "\n",
    "# Preparación para la inferencia en el conjunto de prueba\n",
    "preds = []\n",
    "targets = []\n",
    "\n",
    "print('Running inference on test data...')\n",
    "for imgs, labels in tqdm(validation_generator):\n",
    "    # Realiza la predicción para el batch actual\n",
    "    batch_preds = model.predict(imgs)\n",
    "    # Almacena las predicciones como clases predichas más probables\n",
    "    preds.extend(tf.argmax(batch_preds, axis=1).numpy())\n",
    "    # Directamente agregar las etiquetas numéricas\n",
    "    targets.extend(labels)\n",
    "\n",
    "# Generar y visualizar las métricas de clasificación\n",
    "print('Calculating classification metrics...')\n",
    "report = classification_report(targets, preds,  target_names=['Negativo', 'Positivo']) \n",
    "\n",
    "# Opcionalmente, guardar el informe de clasificación\n",
    "with open(f'weights/{model_name}/version_{version}/classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
